{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from nibabel.testing import data_path\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "ROOT_DIR = \"./\"\n",
    "DATA_DIR = './nifti/'\n",
    "TRAIN_DATA_PROPORTION = 0.8 # Proportion of data used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to label data: 0 :\t ./nifti/515/Shank_515-labels.nii\n",
      "Added to train data: 0 :\t ./nifti/515/Shank_515.ibw.nii\n",
      "Added to train data: 1 :\t ./nifti/497/Shank_497.ibw.nii\n",
      "Added to label data: 1 :\t ./nifti/497/Shank_497-labels.nii\n",
      "Added to train data: 2 :\t ./nifti/520/Shank_520.ibw.nii\n",
      "Added to label data: 2 :\t ./nifti/520/Shank_520-labels.nii\n",
      "Added to train data: 3 :\t ./nifti/536/Shank_536.ibw.nii\n",
      "Added to label data: 3 :\t ./nifti/536/Shank_536-labels.nii\n",
      "Added to train data: 4 :\t ./nifti/534/Shank_534.ibw.nii\n",
      "Added to label data: 4 :\t ./nifti/534/Shank_534-labels.nii\n",
      "Added to train data: 5 :\t ./nifti/541/Shank_541.ibw.nii\n",
      "Added to label data: 5 :\t ./nifti/541/Shank_541-labels.nii\n",
      "Added to label data: 6 :\t ./nifti/521/Shank_521-labels.nii\n",
      "Added to train data: 6 :\t ./nifti/521/Shank_521.ibw.nii\n",
      "Added to label data: 7 :\t ./nifti/506/Shank_506-labels.nii\n",
      "Added to train data: 7 :\t ./nifti/506/Shank_506.ibw.nii\n",
      "Added to label data: 8 :\t ./nifti/542/Shank_542-labels.nii\n",
      "Added to train data: 8 :\t ./nifti/542/Shank_542.ibw.nii\n",
      "Added to train data: 9 :\t ./nifti/522/Shank_522.ibw.nii\n",
      "Added to label data: 9 :\t ./nifti/522/Shank_522-labels.nii\n",
      "Added to label data: 10 :\t ./nifti/496/Shank_496-labels.nii\n",
      "Added to train data: 10 :\t ./nifti/496/Shank_496.ibw.nii\n",
      "Added to label data: 11 :\t ./nifti/528/Shank_528-labels.nii\n",
      "Added to train data: 11 :\t ./nifti/528/Shank_528.ibw.nii\n",
      "Added to label data: 12 :\t ./nifti/499/Shank_499-labels.nii\n",
      "Added to train data: 12 :\t ./nifti/499/Shank_499.ibw.nii\n",
      "Added to train data: 13 :\t ./nifti/550/Shank_550c.ibw.nii\n",
      "Added to label data: 13 :\t ./nifti/550/Shank_550c-labels.nii\n",
      "Added to train data: 14 :\t ./nifti/523/Shank_523.ibw.nii\n",
      "Added to label data: 14 :\t ./nifti/523/Shank_523-labels.nii\n",
      "Added to train data: 15 :\t ./nifti/527/Shank_527.ibw.nii\n",
      "Added to label data: 15 :\t ./nifti/527/Shank_527-labels.nii\n",
      "Dataset shape:  (16, 128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Getting all the data files\n",
    "dataset_data, dataset_labels = [], []\n",
    "dataset_data_headers, dataset_labels_headers = [], []\n",
    "i_data, i_label = 0, 0\n",
    "for subdir, dirs, files in os.walk(DATA_DIR):\n",
    "    for file in files:\n",
    "        filename = os.path.join(subdir, file)\n",
    "        if filename.endswith(\".nii\") and not \"nifti_em\" in filename:\n",
    "            # Adding source data into dataset_data\n",
    "            if not (\"-labels\" in filename):\n",
    "                tmp = nib.load(filename)\n",
    "                dataset_data.append(tmp.get_fdata())\n",
    "                dataset_data_headers.append(tmp.header)\n",
    "                print(\"Added to train data:\", i_data,\":\\t\", filename)\n",
    "                i_data += 1\n",
    "            # Adding label data into dataset_labels\n",
    "            else:\n",
    "                tmp = nib.load(filename)\n",
    "                dataset_labels.append(tmp.get_fdata())\n",
    "                dataset_labels_headers.append(tmp.header)\n",
    "                print(\"Added to label data:\", i_label, \":\\t\", filename)\n",
    "                i_label += 1\n",
    "            \n",
    "dataset_data = np.array(dataset_data, dtype=np.float32) \n",
    "dataset_labels = np.array(dataset_labels, dtype=np.int8)\n",
    "\n",
    "# Verifying training data is valid\n",
    "assert(dataset_data.shape == dataset_labels.shape)\n",
    "print(\"Dataset shape: \", dataset_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainingData(data, proportion):\n",
    "    split_index = int(len(data)*proportion)\n",
    "    tmp = np.split(data, [split_index, len(data)])\n",
    "    return tmp[0], tmp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 12 \n",
      "Testing data:  4\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into testing and training sets\n",
    "X_train, X_test  = splitTrainingData(dataset_data, TRAIN_DATA_PROPORTION)\n",
    "Y_train, Y_test  = splitTrainingData(dataset_labels, TRAIN_DATA_PROPORTION)\n",
    "\n",
    "# Verifying training data is valid\n",
    "assert(X_train.shape == Y_train.shape and X_test.shape == Y_test.shape)\n",
    "print(\"Training data:\", X_train.shape[0], \"\\nTesting data: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the data ha the same shape.\n"
     ]
    }
   ],
   "source": [
    "# Printing maximum value for each dataset\n",
    "shape = Y_train[0].shape\n",
    "for data in Y_train:\n",
    "    assert data.shape == shape\n",
    "for data in Y_test:\n",
    "    assert data.shape == shape\n",
    "for data in X_train:\n",
    "    assert data.shape + shape\n",
    "for data in X_test:\n",
    "    assert data.shape == shape\n",
    "print(\"All the data ha the same shape.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (128, 128, 128)\n",
      "Data type of label: int8\n",
      "Data type of data: float32\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape:\", Y_train[0].shape)\n",
    "print(\"Data type of label:\", Y_train[0].dtype)\n",
    "print(\"Data type of data:\", X_train[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value a data from Y_train: 2\n",
      "Max value a data from Y_train: 2\n",
      "Max value a data from Y_train: 2\n",
      "Max value a data from Y_train: 2\n",
      "Max value a data from Y_train: 2\n",
      "Max value a data from Y_train: 2\n",
      "Max value a data from Y_train: 2\n",
      "Max value a data from Y_train: 2\n",
      "Max value a data from Y_train: 2\n",
      "Max value a data from Y_train: 2\n",
      "Max value a data from Y_train: 2\n",
      "Max value a data from Y_train: 2\n",
      "Max value a data from Y_test: 2\n",
      "Max value a data from Y_test: 2\n",
      "Max value a data from Y_test: 1\n",
      "Max value a data from Y_test: 2\n",
      "Reformated labels\n"
     ]
    }
   ],
   "source": [
    "# Printing maximum value for each dataset\n",
    "for data in Y_train:\n",
    "    print(\"Max value a data from Y_train:\",np.max(data))\n",
    "for data in Y_test:\n",
    "    print(\"Max value a data from Y_test:\",np.max(data))\n",
    "\n",
    "def removeUnusedLabels(dataset):\n",
    "    f = np.vectorize(lambda x: 1 if x == 2. else 0, otypes=[np.int8])\n",
    "    return f(dataset)\n",
    "\n",
    "Y_train = removeUnusedLabels(Y_train)\n",
    "Y_test  = removeUnusedLabels(Y_test)\n",
    "\n",
    "# Verifying label data validity\n",
    "assert np.max(Y_train) == 1., \"Y_train has \"+str(np.max(Y_train))+\", expected 1.\"\n",
    "assert np.max(Y_test) == 1., \"Y_test has \"+str(np.max(Y_test))+\", expected 1.\"\n",
    "assert(X_train.shape == Y_train.shape and X_test.shape == Y_test.shape)\n",
    "print(\"Reformated labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "#r = R.from_matrix(np.random.random_sample((3, 3)))\n",
    "#rotated = r.apply(X_test[0])\n",
    "#print(rotated.shape, X_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import scipy\n",
    "#import numba \n",
    "\n",
    "#@cuda.jit('(float32[:], float32[:])(float32[:], float32[:], float32)')\n",
    "#@jit\n",
    "def random_rotation_3d(batch1, batch2, max_angle=180.):\n",
    "    \"\"\" Randomly rotate an image by a random angle (-max_angle, max_angle).\n",
    "\n",
    "    Arguments:\n",
    "    max_angle: `float`. The maximum rotation angle.\n",
    "\n",
    "    Returns:\n",
    "    batch of rotated 3D images\n",
    "    \"\"\"batch1.shape\n",
    "    assert \n",
    "    size = batch1.shape\n",
    "    batch1 = np.squeeze(batch1)\n",
    "    batch2 = np.squeeze(batch2)\n",
    "    batch1_rot = np.zeros(batch1.shape, dtype=batch1.dtype)\n",
    "    batch2_rot = np.zeros(batch2.shape, dtype=batch2.dtype)\n",
    "    for i in range(batch1.shape[0]):\n",
    "        if bool(random.getrandbits(1)):\n",
    "            image1b1 = np.squeeze(batch1[i])\n",
    "            image1b2 = np.squeeze(batch2[i])\n",
    "            # rotate along z-axis\n",
    "            angle = random.uniform(-max_angle, max_angle)\n",
    "            image2b1 = scipy.ndimage.interpolation.rotate(image1b1, angle, mode='nearest', axes=(0, 1), reshape=False)\n",
    "            image2b2 = scipy.ndimage.interpolation.rotate(image1b2, angle, mode='nearest', axes=(0, 1), reshape=False)\n",
    "\n",
    "            # rotate along y-axis\n",
    "            angle = random.uniform(-max_angle, max_angle)\n",
    "            image3b1 = scipy.ndimage.interpolation.rotate(image2b1, angle, mode='nearest', axes=(0, 2), reshape=False)\n",
    "            image3b2 = scipy.ndimage.interpolation.rotate(image2b2, angle, mode='nearest', axes=(0, 2), reshape=False)\n",
    "\n",
    "            # rotate along x-axis\n",
    "            angle = random.uniform(-max_angle, max_angle)\n",
    "            batch1_rot[i] = scipy.ndimage.interpolation.rotate(image3b1, angle, mode='nearest', axes=(1, 2), reshape=False)\n",
    "            batch2_rot[i] = scipy.ndimage.interpolation.rotate(image3b2, angle, mode='nearest', axes=(1, 2), reshape=False)\n",
    "        else:\n",
    "            batch1_rot[i] = batch1[i]\n",
    "            batch2_rot[i] = batch2[i]\n",
    "    return batch1_rot.reshape(size), batch2_rot.reshape(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_r, Y_train_r = random_rotation_3d(X_train, Y_train)\n",
    "assert X_train.shape == X_train_r.shape and Y_train.shape == Y_train_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot3D: https://stackoverflow.com/questions/18789232/rotate-a-3d-object-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmenting dataset\n",
    "X_train_bk = X_train\n",
    "Y_train_bk = Y_train\n",
    "for i in range(5):\n",
    "    X_train_r, Y_train_r = random_rotation_3d(X_train_bk, Y_train_bk)\n",
    "    X_train = np.concatenate((X_train, X_train_r), axis=0)\n",
    "    Y_train = np.concatenate((Y_train, Y_train_r), axis=0)\n",
    "print(X_train_bk.shape, X_train.dhape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from numpy import sin, cos\n",
    "theta = np.radians(30)\n",
    "for s, e in combinations(np.array(list(product(d,d,d))), 2):\n",
    "    if np.sum(np.abs(s-e)) == d[1]-d[0]:\n",
    "        s_rotated = [s[0] * cos(theta) - s[1] * sin(theta), \n",
    "                     s[0] * sin(theta) + s[1] * cos(theta),\n",
    "                     s[2]]\n",
    "        e_rotated = [e[0] * cos(theta) - e[1] * sin(theta), \n",
    "                     e[0] * sin(theta) + e[1] * cos(theta),\n",
    "                     e[2]]      \n",
    "        ax.plot3D(*zip(s_rotated,e_rotated), color=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping data to fit in the model\n",
    "X_test  = X_test.reshape((X_test.shape[0], 128,128,128,1))\n",
    "X_train = X_train.reshape((X_train.shape[0], 128,128,128,1))\n",
    "Y_test  = Y_test.reshape((Y_test.shape[0], 128,128,128,1))\n",
    "Y_train = Y_train.reshape((Y_train.shape[0], 128,128,128,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from https://github.com/zhixuhao/unet/blob/master/model.py\n",
    "\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as keras\n",
    "\n",
    "\n",
    "def unet3D(pretrained_weights = None, input_size = (128,128,128,1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv3D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv3D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "    conv2 = Conv3D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv3D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "    conv3 = Conv3D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv3D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
    "    \n",
    "    conv5 = Conv3D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv5 = Conv3D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up7 = Conv3D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(drop5))\n",
    "    merge7 = concatenate([conv3,up7], axis = 4)\n",
    "    conv7 = Conv3D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv3D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv3D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 4)\n",
    "    conv8 = Conv3D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv3D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv3D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 4)\n",
    "    conv9 = Conv3D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv3D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv3D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv3D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs, conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "    #TODO: custom accuracy ou une accuracy plus adaptée\n",
    "    \n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0131 09:28:41.095253 139931699160896 deprecation.py:506] From /home/broseau/.local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 12 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 128, 128, 128 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 128, 128, 128 110656      conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 64, 64, 64, 6 0           conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 64, 64, 64, 1 221312      max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 64, 64, 64, 1 442496      conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 32, 32, 32, 1 0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 32, 32, 32, 2 884992      max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 32, 32, 32, 2 1769728     conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 16, 16, 16, 2 0           conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 16, 16, 16, 5 3539456     max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 16, 16, 16, 5 7078400     conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16, 16, 16, 5 0           conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d (UpSampling3D)    (None, 32, 32, 32, 5 0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 32, 32, 32, 2 1048832     up_sampling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 32, 5 0           conv3d_5[0][0]                   \n",
      "                                                                 conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 32, 32, 32, 2 3539200     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 32, 32, 32, 2 1769728     conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)  (None, 64, 64, 64, 2 0           conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 64, 64, 64, 1 262272      up_sampling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 64, 2 0           conv3d_3[0][0]                   \n",
      "                                                                 conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 64, 64, 64, 1 884864      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 64, 64, 64, 1 442496      conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)  (None, 128, 128, 128 0           conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 128, 128, 128 65600       up_sampling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 128 0           conv3d_1[0][0]                   \n",
      "                                                                 conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 128, 128, 128 221248      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 128, 128, 128 110656      conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 128, 128, 128 3458        conv3d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 128, 128, 128 3           conv3d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,397,189\n",
      "Trainable params: 22,397,189\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = unet3D()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 50\n",
    "BATCH_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "WARNING:tensorflow:From <ipython-input-15-74b6d4946269>:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Using GPU:  True\n"
     ]
    }
   ],
   "source": [
    "# Training Model on GPU if available\\n\",\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "device = tf.device('/GPU:0') if tf.test.is_gpu_available() else tf.device('/CPU:0')\n",
    "print(\"Using GPU: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples, validate on 4 samples\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 13s 1s/sample - loss: 0.1887 - accuracy: 0.9145 - val_loss: 0.0958 - val_accuracy: 0.9393\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 4s 320ms/sample - loss: 0.0985 - accuracy: 0.9222 - val_loss: 0.0669 - val_accuracy: 0.9407\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 4s 320ms/sample - loss: 0.0830 - accuracy: 0.9229 - val_loss: 0.0629 - val_accuracy: 0.9409\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 4s 320ms/sample - loss: 0.0802 - accuracy: 0.9230 - val_loss: 0.0615 - val_accuracy: 0.9410\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 4s 318ms/sample - loss: 0.0794 - accuracy: 0.9231 - val_loss: 0.0612 - val_accuracy: 0.9410\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 4s 319ms/sample - loss: 0.0792 - accuracy: 0.9231 - val_loss: 0.0611 - val_accuracy: 0.9410\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 4s 318ms/sample - loss: 0.0791 - accuracy: 0.9231 - val_loss: 0.0611 - val_accuracy: 0.9410\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 4s 319ms/sample - loss: 0.0790 - accuracy: 0.9231 - val_loss: 0.0611 - val_accuracy: 0.9410\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 4s 319ms/sample - loss: 0.0790 - accuracy: 0.9231 - val_loss: 0.0611 - val_accuracy: 0.9410\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 4s 319ms/sample - loss: 0.0790 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 4s 320ms/sample - loss: 0.0790 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 4s 321ms/sample - loss: 0.0790 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 4s 329ms/sample - loss: 0.0790 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 4s 316ms/sample - loss: 0.0790 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 4s 308ms/sample - loss: 0.0790 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 4s 308ms/sample - loss: 0.0790 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 4s 309ms/sample - loss: 0.0790 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 4s 326ms/sample - loss: 0.0790 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 4s 309ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 4s 309ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 4s 308ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 4s 307ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 4s 309ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 4s 309ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 4s 309ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 4s 309ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 4s 309ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 4s 307ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0610 - val_accuracy: 0.9410\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 4s 312ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0609 - val_accuracy: 0.9410\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 4s 318ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0609 - val_accuracy: 0.9410\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 4s 307ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0609 - val_accuracy: 0.9410\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 4s 310ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0609 - val_accuracy: 0.9410\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 4s 312ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0609 - val_accuracy: 0.9410\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 4s 307ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0609 - val_accuracy: 0.9410\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 4s 311ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0609 - val_accuracy: 0.9410\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 4s 312ms/sample - loss: 0.0789 - accuracy: 0.9231 - val_loss: 0.0609 - val_accuracy: 0.9410\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 4s 309ms/sample - loss: 0.0788 - accuracy: 0.9231 - val_loss: 0.0609 - val_accuracy: 0.9410\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 4s 309ms/sample - loss: 0.0786 - accuracy: 0.9231 - val_loss: 0.0603 - val_accuracy: 0.9410\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 4s 309ms/sample - loss: 0.0779 - accuracy: 0.9231 - val_loss: 0.0593 - val_accuracy: 0.9410\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 4s 307ms/sample - loss: 0.0774 - accuracy: 0.9231 - val_loss: 0.0592 - val_accuracy: 0.9410\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 4s 308ms/sample - loss: 0.0771 - accuracy: 0.9231 - val_loss: 0.0591 - val_accuracy: 0.9410\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 4s 315ms/sample - loss: 0.0771 - accuracy: 0.9231 - val_loss: 0.0591 - val_accuracy: 0.9410\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 4s 312ms/sample - loss: 0.0770 - accuracy: 0.9231 - val_loss: 0.0591 - val_accuracy: 0.9410\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 4s 314ms/sample - loss: 0.0770 - accuracy: 0.9231 - val_loss: 0.0591 - val_accuracy: 0.9410\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 4s 312ms/sample - loss: 0.0770 - accuracy: 0.9231 - val_loss: 0.0591 - val_accuracy: 0.9410\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 4s 308ms/sample - loss: 0.0770 - accuracy: 0.9231 - val_loss: 0.0591 - val_accuracy: 0.9410\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 4s 307ms/sample - loss: 0.0770 - accuracy: 0.9231 - val_loss: 0.0591 - val_accuracy: 0.9410\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 4s 308ms/sample - loss: 0.0770 - accuracy: 0.9231 - val_loss: 0.0591 - val_accuracy: 0.9410\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 4s 307ms/sample - loss: 0.0770 - accuracy: 0.9231 - val_loss: 0.0591 - val_accuracy: 0.9410\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 4s 310ms/sample - loss: 0.0770 - accuracy: 0.9231 - val_loss: 0.0591 - val_accuracy: 0.9410\n"
     ]
    }
   ],
   "source": [
    "with device:\n",
    "    model.fit(X_train, Y_train,\n",
    "        epochs=NB_EPOCHS, batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn.plotting as nplt \n",
    "\n",
    "def generateMask(prediction, threshold=0.5):\n",
    "    \"\"\" Returns prediction as an array containing 0 and 1.\n",
    "        threshold is applied on each values \"\"\"\n",
    "    f = lambda a: 1 if a >= threshold else 0\n",
    "    return np.where(prediction >= threshold, 1, 0).astype(np.int8)\n",
    "\n",
    "def saveMask(data, path, header=None):\n",
    "    img = nib.Nifti1Image(data, np.eye(4))\n",
    "    if header is not None:\n",
    "        img.header = header\n",
    "    nib.save(img, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nilearn.plotting.displays.OrthoSlicer at 0x7f6877ff2810>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAADJCAYAAAAHFcoVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAARGElEQVR4nO3da2xU1f7G8adQbBoK9PSiA5ZAgKBGQQIGPImXSpAGTbjUCwKVAk2FlIsYjBHBBC+tCgkvDIHkxGgUDCACEomWcAnxBX8v/EmLYKwEaUhTICKttCiHW88LnLEt0+lMu2fvtfb+fpJJoNPOXjP7N+uZ39p7ZlJaWlpaBAAAjNPD6wEAAIDoCGkAAAxFSAMAYChCGgAAQxHSAAAYipAGAMBQhDQAAIYipAEAMBQhDQCAoQhpAAAMRUgDAGAoQhoAAEMR0gAAGIqQBgDAUIQ0AACGIqQBADAUIQ0AgKEIaQAADEVIAwBgKEIaAABDpca68vEez7g1DgAAAmvvjW1Rf04nDQCAoQhpAAAMRUgDAGAoQhoAAEMR0gAAGIqQBgDAUIS0w2paqlTTUuX1MABHUdeIhrpIvpjvk+6urfX/UVboX1Gvu3C2QdMHvJDMzXuiSY1eD8EVsfat5N/9G1RBqevu6uh54dfnQ1DqorP5TkrePk5qSMe6U53dYZits/3H/kUQdVT3fnk+7Klv2zWPL2y++fMd8XXTBQNGOT4mN8Sz/5K1j5O+3D148GDt27cv2ZuBBwYPHqz09HRlZGQoFAppzpw5am5u9npYgKf8NOftqa9qc3Hi9mzl1XyX1E4a/vfll19qwoQJOnv2rAoKCvTOO++ovLzc62EBiJPbwRnP9kztuL2Y7zhxDI4IhUIqKChQVZW9r5QBIB5uznd00nBEXV2dvv76a40fP97roQCIwYYl5/ZjNK2zdnO+o5NGt0ydOlV9+vTRwIEDdfvtt+uNN97wekgAOmBDQEfj1DHx7vJiviOk0S1ffPGFmpqadPDgQf388886f/6810MC0IqTJ355zekT2RLlxXxHSMMRjz76qObMmaOXX37Z66EA+JsfgtlEbs53rhyTvnr1qi5fvvzPRlNTlZrK4XC/Wbp0qQYPHqzq6mrdf//9Xg8H8Ey0OQ/+4tZ850on/cQTTyg9PT1yWbVqlRubhctyc3M1e/Zsvfnmm14PBfCUCXNeELpoL++jW/Nd0l/e1dbWJnsT8Ei0fbthwwb3BwIYpKM57/GKZ1wbQxAC2m1ezXeswQCATwQxnFvfZ9PequWEpC53Xzjb0KXrYL7O9h/7F0HUUd3zfLBbPPsvWfs4qZ20H7/1BTexb4Fb8bzwJy/3K2/BAgAfCOJSd3t+fAwIaQAADEVIA4Dl/NhBdpXfHgtCGgAs5rdQQluENAAAhiKkAQC+4pcvFJH4MBMAsI5fAihZ/PShJnTSAAAYipAGAPiKn5a7CWkAAAxFSAOAJfzUIbrBD48VIQ0A8C3bg5qQBgAL2B42XrL5sSOkAQAwFCENAIChCGkAMBgniznD1seQTxwDAEPZGiymav142vKpZHTSAGAgAhoSIQ0AgLEIaQBA4NiyUkFIAwBgKEIaAAxjS5eH5COkAQAwFCENAIChCGkAMIwt7+FF8hHSAAAYipAGAMNw4hjCCGkAAAxFSAMAYChCGgAAQxHSAAAYipAGAMBQhDQAAIZK9XoAAGCKwy0HvR6CJGl8YbPXQ4hL1fH/SpLGF9Z5PJKuqW5p9HoIkqQHUvI7vI5OGgAAQ9FJA8DfYnU0btqzw44PMwl30Ad25Hk8kq6x4eNX6aQBBBKf6gUb0EkDCAyCGWE2dNESIQ0gAAhn2IrlbgC+0j6QbQxoW7o8JB8hDQCAoVjuBmCs1l1wuLsM/yxatxm+zsbuGYiGkAZglI4CNtYyNsvD8CuWuwF4rrud7576KrpnxM2mF3V00gCMQMgCt6KTBgDAUHTSADxD9ww32bTMHUZIA3AFgZyYggGjeMzAcjeA5CNs4DUbu2iJThpAEhDKzqCbBp00AACGIqQBOIrOD3AOy90AHEE4J0frY6k8xomz9Vh0mO9COloR276TAFMQEt7hsQ8mX4R0Z8Ub6/p4AjyRJ0d2f2e2CXhpT31V5KQl6tUMnESWOD/UrvUh7cRn/obF+ladeN3/7+a//5UZ1zZjbbsznY3NDwWK5OvsCy321FdpfGHndW269iHH88O//LRvOXEMAABDWd1JO73003ppz+1lpVjfkdvR7zp5mwiOIC+Z2v5c8Gp+sont+7g9a0M6WUVqevF3ZXzt/8ZvRYzOmV7XbuD4OmzEcrdhok2m4e/KdWqiZcIOFvb3P/zyvdO82LhVwYBRvnxcrO2k/cyNSYSuIhj8EEiIjqXvYKCTBgDAUNZ10rxqdA4nlvkTzxEEid/nLzppMKkDFvN7SMUShPtuVSdNmAAd4/kRXEE7Ph2EcA6jkwZ8ICiTMxA0hDQAAIayarkbwK3oohHm96+1DNIydxghDVjIjxOwG4I4ydsu6PvMmpBmUgJ4HiB+tp9MFvRwDrMmpIEgs3Wihfec+ApeNxHObXHiGAAAhqKTBgzSusMpGDDK6I4H9jLlBDO65s4R0oChCGi4we1j1wRzYqwIaSYrAEiuZHbXBHPXWRHSQBDwYhSm6G53TSg7hxPHAAAwFJ00YAC6aJios464uqUxrt9D19FJQxIh4ZU99VU89gA6REgDCAS6Pdgo5nL34ZaDLg0jtvGFzV4PIW5Vx/8rSRpfWOfxSBIXXrqCe2ypbZvrOqy6pVF9lKm7Ughr2INOGgAAQ8XspB9IyXdpGLHt2WHPMbtwp3FgR57HI0kcy4Hu2FNf1erTxDK9Hk5cbK5r6WZtP5Di9SiAxNFJAx7gZDH38OITNuMtWJDERJZshDKArrAipPmiAdiKuvUOLzzhByx3AwBgKCs6acA2dNAAnGBNJ83SFWxBQHurYMAo5gv4hjUhjeRhQgMAMxHSgIPoor3FC074DSENAIChOHEswOg6nEUX7R1qGX5lVUjzfmkgmAhhBJVVIS3982QlrLuHSQ+mo0YBC0M6jLDuOiY/Z1GDzqNGgZs4cSxgmPwAwB6ENAAAhrI+pOkM48djBRtQp8A/rD0m3RpnfcfGpAfTUaNAdL4IaYkTyaJh4ks+6q17qFEgNt+EdBhd9U1MfjARdQkkxvpj0gAA+JXvOmkp2EvfdCruCWJ9AXCXL0M6rHVgBWFCJaBhKmoT6Bpfh3Rrfj5WzQToPr/WkhOoR8A5gQlpqePJw8YJl4nQOzbWS7JQh0ByceIYAACGClQn3ZH23UBXOqXwbVS3NDoypo5uH3BT68NE1f+XEfkZAHcQ0lE4MQkxkcF0rd8FEateCwaMirz4pK4BdxHSgM+0fwti+3c5tA9aghcwFyENGMLp9/dHC18CGbALJ44BAGAoOmnAMHS7AMLopIEEJSNECWYA0dBJA13gxPFjghlAZwhpoBsIWgDJxHI3AACGIqQBADAUIQ0AgKEIaQAADEVIAwBgqJhnd2+t/4+yQv9yayxRXTjboOkDXvB0DHCf17VH3QWTl3VHzSGamJ201wFtyhjgPq/3u9fbhze83O/UHKJxZbn7woULmj59urKzs5WTk6NZs2bp4sWLketff/11jRgxQqmpqVq1apUbQ0JA7Nu3T6NHj1bv3r2Vl5enzz77TJL0yy+/aMqUKcrNzVVWVpYKCgpUU1Pj8WjhF1euXNE999yjvLy8qNd/8sknSklJ0QcffODyyGAbV0J65cqVamho0KlTp3Ty5EmdO3euTRgPGzZMq1ev1pNPPunGcBAQP/30k2bOnKny8nL98ccfqq6u1pgxYyRJjY2Nmjx5smpqanTu3DmNHTtWU6ZM8XjE8Is1a9YoNzc36nUNDQ2qqKjQvffe6/KoYKNOQ3rNmjV66qmn2vxsyZIlevHFF+PeyKlTpzR16lT17dtX/fr107Rp03T8+PHI9cXFxZo0aZL69OmTwNDhZydPnlRWVpaOHDkiSaqvr1dubq4OHjwY9228/fbbmj9/viZNmqTU1FRlZ2dr6NChkqSxY8eqpKREWVlZ6tWrl1566SXV1NTo999/T8bdgSW2bt2qjIyMyCUtLU35+fkJ3capU6e0adMmLV++POr1y5cv15IlS5STk+PAiOF3nYZ0UVGRKisr1djYKEm6du2atmzZotmzZ6usrEyZmZlRLyNHjozcxsKFC7V79241NDSooaFB27dv16RJk5J3rzzUR5nqo0yvh2G9oUOH6r333lNRUZH+/PNPzZ07V8XFxcrPz4+77r799ltJ0ogRI9S/f38VFRXpwoULUbf3zTffKBQKKTs725X7Z5ug1PX06dPV3Nys5uZm1dfXa8iQIZoxY4befffdDmsuM7Pt47J48WJVVFQoPT39ltv//vvvdfjwYS1YsMCtu5RUQakLL3Ua0v3799cjjzyibdu2SZIqKyuVk5OjMWPGaP369WpsbIx6OXr0aOQ2Ro8erStXrig7O1vZ2dnq2bOnysrKknevPHRXyijdlcLnOTuhtLRUw4YN07hx43TmzBmVl5dLUtx1V1dXp40bN2r79u06ceKE/vrrLy1evPiW7dTV1WnhwoVau3ata/fNNkGr6xs3bmjmzJnKz8/X/Pnz9eqrr3ZYc+EGRpJ27typ69eva9q0abfc5vXr11VWVqZ169apRw9/vPs1aHXhhbgqpbi4WJs2bZIkbdq0Sc8//3xCG3n22Wc1fPhwNTU16eLFixo6dKiKiooSHy0Cp7S0VMeOHdPixYuVlpaW0N+mp6dr7ty5Gj58uDIyMvTaa6/pq6++avM7v/32myZOnKiysjLNmDHDyaHDYitWrFBTU5Pef//9uP/m0qVLeuWVVzr8m/Xr12vkyJF68MEHnRomAiCukJ46daqOHj2qY8eOaffu3Zo1a5YkacGCBW2O37S+tD4poqqqSvPnz1fv3r2VkZGhBQsW3DJZAu01Nzdr6dKlKikp0apVqyJL1fHW3ciRI5WSkhL5f+t/SzdP4Jk4caImT56sFStWuHOnYLwtW7Zo8+bN+vzzz9WrVy9JUkVFRYc1l5GRIUk6ceKEamtr9fDDDysUCqmwsFBnzpxRKBRSbW2t9u/fr507dyoUCikUCunQoUNatmyZFi1a5OXdheFSWlpaWuL5xdLSUn333XfKycnRgQMHEtrIY489pvvuu0+rV6+WJC1btkxVVVU6dOiQJOnq1au6fv265s2bpyFDhmjlypXq1auXevbsKUl6vMczCW0P9tt7Y5tKSkrU3NysrVu36oUXXlBjY2PkLVTx+PDDD/XWW29p//79CoVCmjNnjtLS0rRx40ZdvHhREyZM0NixY7Vu3bqof0/dBc/q/39NEydO1N69ezVqVGLLuNeuXdP58+cj/z906JAWLVqkI0eOKDc3V01NTbp8+XLk+sLCQj399NMqKSlRv379JFFzQbb3xraoP4/7wEhxcbF+/PHHhJe6pZuTZW1trfLy8nTnnXfq119/1ccffxy5vrS0VOnp6dq8ebPKy8uVnp6ujRs3Jrwd+MeuXbtUWVmpDRs2SJLWrl2rI0eO6NNPP437NubNm6fZs2dr3LhxGjRokNLS0iJLkTt37tQPP/ygjz76qE1HdPr06aTcH9hh165damho0EMPPRSpiXhPck1NTY10yaFQSFlZWerRo4dCoZB69uypzMzMNtffdtttkXe8AB2Ju5M+ffq07r77bp09e1Z9+/ZN9rja4NVl8HT0qtJN1F3weF131FxwdauTvnHjhtauXavnnnvO9YAGACCoOu2kL126pDvuuEODBg1SZWWlBg4c6NbYAAAItLiXuwEAgLv88Y56AAB8iJAGAMBQhDQAAIYipAEAMBQhDQCAoQhpAAAMRUgDAGAoQhoAAEMR0gAAGIqQBgDAUIQ0AACGIqQBADAUIQ0AgKEIaQAADEVIAwBgKEIaAABDEdIAABiKkAYAwFCENAAAhiKkAQAw1P8AiGCiVI/RonwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 475.2x187.2 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "saveMask(dataset_labels[-1], \"ground_truth.nii\")\n",
    "nplt.plot_img(\"ground_truth.nii\", cut_coords=[62, 81, 44])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = generateMask(model.predict(X_test))\n",
    "predictions = predictions.reshape((predictions.shape[0], 128,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nilearn.plotting.displays.OrthoSlicer at 0x7f6877e9ce50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAADJCAYAAAAHFcoVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAANBklEQVR4nO3dfUyVdR/H8Q9yiJ0JSjzUsXAyYVYryWnD/uiBtsJRm6I9mEqAMoShmM3W8qGNHqDSjT+a0621WkFTMkcuV2xqc/3BevAmNGuRM5hjPizjEBzLqcD9R3fccXvAwy3nur6c835tZxMuOdfvOtfvXG9+B47GDA4ODgoAAJgzye0BAACA4Ig0AABGEWkAAIwi0gAAGEWkAQAwikgDAGAUkQYAwCgiDQCAUUQaAACjiDQAAEYRaQAAjCLSAAAYRaQBADCKSAMAYBSRBgDAKCINAIBRRBoAAKOINAAARhFpAACMItIAABjlGW3jI5OedGocAABErQMDe4J+npU0AABGEWkAAIwi0gAAGEWkAQAwikgDAGAUkQYAwCgiPc7aB9vUPtjm9jCAccW8RjDMi/Ab9X3S16vx9NtK9t0YdFv3Wb+W3rI6nLt3RZ963B6CI0Y7t1Lknt9oFS3z+nqN9LyI1OdDtMyLa13vpPCd47CupEc7qGsdMGy71vnj/CIajTTveT5MbKGcv3Cd47C/3J2RkaGDBw+GezdwQUZGhrxerxISEuTz+VRSUqJAIOD2sABXcc2LTG5d7/iZNK7Lp59+qkAgoLa2Nn333Xd6/fXX3R4SAISFG9c7Io1x4fP5tGDBArW18UskACKbk9c7Io1x0dXVpc8//1xZWVluDwUAwsrJ6x2RxnUpKChQYmKipk+frptuukkvv/yy20MCgLBw43pHpHFdPvnkE/X19enw4cP66aefdP78ebeHBABh4cb1jkhjXDz44IMqKSnR888/7/ZQACCsnLzehfUfM/nb5cuXdfHixf/u1OORx+PIruGg9evXKyMjQ0ePHtXdd9/t9nAA1wS75iGyOHW9c2Ql/eijj8rr9Q7dqqurndgtHJaWlqaioiK98sorbg8FcBXXvMjn1PUu7N/edXZ2hnsXcEmwc7tz507nBwIYMtI175HaJ50dCMaVW9c7fiYNAIBRYY1091n//7UN9l3r/HF+EY1Gmvc8Hya2UM5fuM5xWF/ujsT/9QV/4dwCV+N5EZncPK+83A0AgFFEGgAAo4g0AABGEWkAAIwi0gAAGEWkAQAwikgDAGAUkQYAwCgiDQCAUUQaAACjiDQAAEYRaQAAjCLSAAAYRaQBADCKSAMAYBSRBgDAKCINAIBRRBoAAKOINAAARhFpAACMItIAABhFpAEAMIpIAwBgFJEGAMAoIg0AgFFEGgAAo4g0AABGEWkAAIwi0gAAGEWkAQAwikgDAGAUkQYAwCgiDQCAUR63BwAAVhwZPOz2ECaUPvVI4nG7XvfE5I64jZU0AABGsZIGgP8YbUWDq/29guZxCx9W0gAAGEWkAQAwikgDAGAUkQYAwCgiDQCAUUQaAACjiDQAAEYRaQAAjCLSAAAYRaQBADCKSAMAYBSRBgDAKCINAIBRRBoAAKOINAAARhFpAACMItIAABhFpAEAMIpIAwBgFJEGAMAoIg0AgFFEGgAAo4g0AABGEWkAAIwi0gAAGEWkAQAwikgDAGAUkQYAwCgiDQCAUUQaAACjiDQAAEYRaQAAjCLSAAAYRaQBADCKSAMAYBSRBgDAKCINAIBRRBoAAKOINAAARhFpAACMItIAABhFpAEAMIpIAwBgFJEGAMAoz2gbjwwedmgYkaNPPZJ47BBZImVeJypJt8XMcXsYQMhYSQMAYNSoK+l7YnIdGkbk+HulwWOHSMK8BtzBShoAAKOINAAARhFpAACMItIAABhFpAEAMIpIAwBgFJEGAMAoIg0AgFFEGgAAo4g0AABGEWkAAIwi0gAAGEWkAQAwikgDAGAUkQYAwCgiDQCAUUQaAACjiDQAAEYRaQAAjCLSAAAYRaQBADCKSAMAYBSRBgDAKCINAIBRRBoAAKOINAAARhFpAACMItIAABhFpAEAMIpIAwBgFJEGAMAoIg0AgFFEGgAAo4g0AABGEWkAAIwi0gAAGEWkAQAwikgDAGAUkQYAwCjPaBsbT7+tZN+NTo0lqO6zfi29ZbWrY4Dz3J57zLvo5Oa8Y84hmFFX0m4H2soY4Dy3z7vb+4c73DzvzDkE48jL3d3d3Vq6dKlSUlKUmpqqFStWqLe3d2j7Sy+9pNmzZ8vj8ai6utqJISFKHDx4UHPnztXkyZOVnp6ujz76SJL0888/a9GiRUpLS1NycrIWLFig9vZ2l0eLSHHp0iXdcccdSk9PD7r9gw8+UExMjN555x2HR4aJxpFIb9myRX6/Xx0dHTp58qTOnTs3LMZZWVnaunWrHnvsMSeGgyjx448/avny5aqpqdHvv/+uo0ePat68eZKknp4eLVy4UO3t7Tp37pxycnK0aNEil0eMSLFt2zalpaUF3eb3+1VbW6s777zT4VFhIrpmpLdt26bHH3982OfWrVunZ599NuSddHR0qKCgQFOmTNHUqVO1ePFi/fDDD0Pbi4uLlZ+fr8TExDEMHZHs5MmTSk5OVmtrqyTp9OnTSktL0+HDh0O+j9dee03l5eXKz8+Xx+NRSkqKMjMzJUk5OTkqLS1VcnKy4uLi9Nxzz6m9vV2//fZbOA4HE0RjY6MSEhKGbvHx8crNzR3TfXR0dKihoUEbN24Mun3jxo1at26dUlNTx2HEiHTXjHRhYaGam5vV09MjSbpy5Yp2796toqIiVVZWKikpKegtOzt76D7WrFmj/fv3y+/3y+/3a+/evcrPzw/fUbkoUUlKVJLbw5jwMjMz9eabb6qwsFB//PGHVq5cqeLiYuXm5oY877766itJ0uzZszVt2jQVFhaqu7s76P6+/PJL+Xw+paSkOHJ8E020zOulS5cqEAgoEAjo9OnTmjlzppYtW6Y33nhjxDmXlDT8camqqlJtba28Xu9V9//NN9/oyJEjqqiocOqQwipa5oWbrhnpadOm6YEHHtCePXskSc3NzUpNTdW8efO0Y8cO9fT0BL0dO3Zs6D7mzp2rS5cuKSUlRSkpKYqNjVVlZWX4jspFt8XM0W0xc9weRkQoKytTVlaW5s+frzNnzqimpkaSQp53XV1dqq+v1969e3XixAn9+eefqqqqumo/XV1dWrNmjerq6hw7tokm2ub1wMCAli9frtzcXJWXl+vFF18ccc79vYCRpKamJvX392vx4sVX3Wd/f78qKyu1fft2TZoUGe9+jbZ54YaQZkpxcbEaGhokSQ0NDXrmmWfGtJOnnnpKs2bNUl9fn3p7e5WZmanCwsKxjxZRp6ysTMePH1dVVZXi4+PH9LVer1crV67UrFmzlJCQoE2bNumzzz4b9nd+/fVX5eXlqbKyUsuWLRvPoWMC27x5s/r6+vTWW2+F/DUXLlzQCy+8MOLX7NixQ9nZ2br33nvHa5iIAiFFuqCgQMeOHdPx48e1f/9+rVixQpJUUVEx7Oc3/7z985ci2traVF5ersmTJyshIUEVFRVXXSyB/xUIBLR+/XqVlpaqurp66KXqUOdddna2YmJihj7+55+lv36BJy8vTwsXLtTmzZudOSiYt3v3bu3atUsff/yx4uLiJEm1tbUjzrmEhARJ0okTJ9TZ2an7779fPp9PS5Ys0ZkzZ+Tz+dTZ2alDhw6pqalJPp9PPp9PLS0t2rBhg9auXevm4cK4mMHBwcFQ/mJZWZm+/vprpaam6osvvhjTTh566CHddddd2rp1qyRpw4YNamtrU0tLiyTp8uXL6u/v16pVqzRz5kxt2bJFcXFxio2NlSQ9MunJMe0PE9+BgT0qLS1VIBBQY2OjVq9erZ6enqG3UIXi3Xff1auvvqpDhw7J5/OppKRE8fHxqq+vV29vrx5++GHl5ORo+/btQb+eeRd9tv5rk/Ly8nTgwAHNmTO2l3GvXLmi8+fPD33c0tKitWvXqrW1VWlpaerr69PFixeHti9ZskRPPPGESktLNXXqVEnMuWh2YGBP0M+H/IOR4uJiff/992N+qVv662LZ2dmp9PR03Xrrrfrll1/0/vvvD20vKyuT1+vVrl27VFNTI6/Xq/r6+jHvB5Fj3759am5u1s6dOyVJdXV1am1t1YcffhjyfaxatUpFRUWaP3++ZsyYofj4+KGXIpuamvTtt9/qvffeG7YiOnXqVFiOBxPDvn375Pf7dd999w3NiVB/ydXj8Qytkn0+n5KTkzVp0iT5fD7FxsYqKSlp2PYbbrhh6B0vwEhCXkmfOnVKt99+u86ePaspU6aEe1zD8N1l9Bnpu0onMe+ij9vzjjkXva5rJT0wMKC6ujo9/fTTjgcaAIBodc2V9IULF3TzzTdrxowZam5u1vTp050aGwAAUS3kl7sBAICzIuMd9QAARCAiDQCAUUQaAACjiDQAAEYRaQAAjCLSAAAYRaQBADCKSAMAYBSRBgDAKCINAIBRRBoAAKOINAAARhFpAACMItIAABhFpAEAMIpIAwBgFJEGAMAoIg0AgFFEGgAAo4g0AABG/RtHIHgMZ4oQPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 475.2x187.2 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "saveMask(predictions[0], \"prediction.nii\")\n",
    "nplt.plot_img(\"prediction.nii\", cut_coords=[62, 81, 44])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ellisdg/3DUnetCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soutenance: \n",
    "\n",
    "## Statistiques\n",
    "## Explication des résultats\n",
    "## Faire un ou plusieurs DICE, Intersection/Union, Jackard\n",
    "## Matrice de confusion\n",
    "## Couches intermédiaires du réseau\n",
    "## Métriques slices par slices\n",
    "## (voir diapo)\n",
    "https://www.rmsb.u-bordeaux.fr/nextcloud/index.php/s/6oMjTeDtmREpMgC\n",
    "\n",
    "https://playground.tensorflow.org\n",
    "\n",
    "Outil pour visualiser des .nii : itksnap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
