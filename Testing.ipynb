{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from nibabel.testing import data_path\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "ROOT_DIR = \"/net/i/broseau/Travail/3A/FouilleExtrcVisu/2019_ENSEIRB_Skull/\"\n",
    "DATA_DIR = '/tmp/broseau_data/nifti/'\n",
    "OUTPUT_DATA_DIR = '/tmp/broseau_data/nifti_out/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to train data: 0 :\t /tmp/broseau_data/nifti/541/Shank_541.ibw.nii\n",
      "Added to label data: 0 :\t /tmp/broseau_data/nifti/541/Shank_541-labels.nii\n",
      "Added to label data: 1 :\t /tmp/broseau_data/nifti/499/Shank_499-labels.nii\n",
      "Added to train data: 1 :\t /tmp/broseau_data/nifti/499/Shank_499.ibw.nii\n",
      "Added to train data: 2 :\t /tmp/broseau_data/nifti/522/Shank_522.ibw.nii\n",
      "Added to label data: 2 :\t /tmp/broseau_data/nifti/522/Shank_522-labels.nii\n",
      "Added to train data: 3 :\t /tmp/broseau_data/nifti/527/Shank_527.ibw.nii\n",
      "Added to label data: 3 :\t /tmp/broseau_data/nifti/527/Shank_527-labels.nii\n",
      "Added to label data: 4 :\t /tmp/broseau_data/nifti/528/Shank_528-labels.nii\n",
      "Added to train data: 4 :\t /tmp/broseau_data/nifti/528/Shank_528.ibw.nii\n",
      "Added to label data: 5 :\t /tmp/broseau_data/nifti/536/Shank_536-labels.nii\n",
      "Added to train data: 5 :\t /tmp/broseau_data/nifti/536/Shank_536.ibw.nii\n",
      "Added to label data: 6 :\t /tmp/broseau_data/nifti/550/Shank_550c-labels.nii\n",
      "Added to train data: 6 :\t /tmp/broseau_data/nifti/550/Shank_550c.ibw.nii\n",
      "Added to label data: 7 :\t /tmp/broseau_data/nifti/496/Shank_496-labels.nii\n",
      "Added to train data: 7 :\t /tmp/broseau_data/nifti/496/Shank_496.ibw.nii\n",
      "Added to label data: 8 :\t /tmp/broseau_data/nifti/542/Shank_542-labels.nii\n",
      "Added to train data: 8 :\t /tmp/broseau_data/nifti/542/Shank_542.ibw.nii\n",
      "Added to label data: 9 :\t /tmp/broseau_data/nifti/506/Shank_506-labels.nii\n",
      "Added to train data: 9 :\t /tmp/broseau_data/nifti/506/Shank_506.ibw.nii\n",
      "Added to train data: 10 :\t /tmp/broseau_data/nifti/520/Shank_520.ibw.nii\n",
      "Added to label data: 10 :\t /tmp/broseau_data/nifti/520/Shank_520-labels.nii\n",
      "Added to label data: 11 :\t /tmp/broseau_data/nifti/523/Shank_523-labels.nii\n",
      "Added to train data: 11 :\t /tmp/broseau_data/nifti/523/Shank_523.ibw.nii\n",
      "Added to label data: 12 :\t /tmp/broseau_data/nifti/521/Shank_521-labels.nii\n",
      "Added to train data: 12 :\t /tmp/broseau_data/nifti/521/Shank_521.ibw.nii\n",
      "Added to train data: 13 :\t /tmp/broseau_data/nifti/497/Shank_497.ibw.nii\n",
      "Added to label data: 13 :\t /tmp/broseau_data/nifti/497/Shank_497-labels.nii\n",
      "Added to train data: 14 :\t /tmp/broseau_data/nifti/534/Shank_534.ibw.nii\n",
      "Added to label data: 14 :\t /tmp/broseau_data/nifti/534/Shank_534-labels.nii\n",
      "Added to label data: 15 :\t /tmp/broseau_data/nifti/515/Shank_515-labels.nii\n",
      "Added to train data: 15 :\t /tmp/broseau_data/nifti/515/Shank_515.ibw.nii\n",
      "Dataset shape:  (16, 128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Getting all the data files\n",
    "dataset_data, dataset_labels = [], []\n",
    "dataset_data_headers, dataset_labels_headers = [], []\n",
    "i_data, i_label = 0, 0\n",
    "for subdir, dirs, files in os.walk(DATA_DIR):\n",
    "    for file in files:\n",
    "        filename = os.path.join(subdir, file)\n",
    "        if filename.endswith(\".nii\") and not \"nifti_em\" in filename:\n",
    "            # Adding source data into dataset_data\n",
    "            if not (\"-labels\" in filename):\n",
    "                tmp = nib.load(filename)\n",
    "                dataset_data.append(tmp.get_fdata())\n",
    "                dataset_data_headers.append(tmp.header)\n",
    "                print(\"Added to train data:\", i_data,\":\\t\", filename)\n",
    "                i_data += 1\n",
    "            # Adding label data into dataset_labels\n",
    "            else:\n",
    "                tmp = nib.load(filename)\n",
    "                dataset_labels.append(tmp.get_fdata())\n",
    "                dataset_labels_headers.append(tmp.header)\n",
    "                print(\"Added to label data:\", i_label, \":\\t\", filename)\n",
    "                i_label += 1\n",
    "            \n",
    "dataset_data = np.array(dataset_data, dtype=np.float32) \n",
    "dataset_labels = np.array(dataset_labels, dtype=np.int8)\n",
    "\n",
    "# Verifying training data is valid\n",
    "assert(dataset_data.shape == dataset_labels.shape)\n",
    "print(\"Dataset shape: \", dataset_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the data ha the same shape.\n"
     ]
    }
   ],
   "source": [
    "# Printing maximum value for each dataset\n",
    "shape = dataset_data[0].shape\n",
    "for data in dataset_data:\n",
    "    assert data.shape == shape\n",
    "for data in dataset_labels:\n",
    "    assert data.shape == shape\n",
    "print(\"All the data ha the same shape.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (128, 128, 128)\n",
      "Data type of label: int8\n",
      "Data type of data: float32\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape:\", dataset_data[0].shape)\n",
    "print(\"Data type of label:\", dataset_labels[0].dtype)\n",
    "print(\"Data type of data:\", dataset_data[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value a data from labels: 2\n",
      "Max value a data from labels: 2\n",
      "Max value a data from labels: 2\n",
      "Max value a data from labels: 2\n",
      "Max value a data from labels: 2\n",
      "Max value a data from labels: 2\n",
      "Max value a data from labels: 2\n",
      "Max value a data from labels: 2\n",
      "Max value a data from labels: 2\n",
      "Max value a data from labels: 2\n",
      "Max value a data from labels: 2\n",
      "Max value a data from labels: 1\n",
      "Max value a data from labels: 2\n",
      "Max value a data from labels: 2\n",
      "Max value a data from labels: 2\n",
      "Max value a data from labels: 2\n",
      "Reformated labels\n"
     ]
    }
   ],
   "source": [
    "# Printing maximum value for each dataset\n",
    "for data in dataset_labels:\n",
    "    print(\"Max value a data from labels:\",np.max(data))\n",
    "\n",
    "def removeUnusedLabels(dataset):\n",
    "    f = np.vectorize(lambda x: 1 if x == 2. else 0, otypes=[np.int8])\n",
    "    return f(dataset)\n",
    "\n",
    "dataset_labels = removeUnusedLabels(dataset_labels)\n",
    "\n",
    "# Verifying label data validity\n",
    "assert np.max(dataset_labels) == 1., \"dataset has \"+str(np.max(dataset_labels))+\", expected 1.\"\n",
    "assert dataset_data.shape == dataset_labels.shape\n",
    "print(\"Reformated labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping data to fit in the model\n",
    "dataset_labels  = dataset_labels.reshape((dataset_labels.shape[0], 128,128,128,1))\n",
    "dataset_data = dataset_data.reshape((dataset_data.shape[0], 128,128,128,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from https://github.com/zhixuhao/unet/blob/master/model.py\n",
    "#TODO: verify shapes and network in itself\n",
    "\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as keras\n",
    "\n",
    "\n",
    "def unet3D(pretrained_weights = None, input_size = (128,128,128,1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "    conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "    conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
    "    \n",
    "    conv5 = Conv3D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv5 = Conv3D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up7 = Conv3D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(drop5))\n",
    "    merge7 = concatenate([conv3,up7], axis = 4)\n",
    "    conv7 = Conv3D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv3D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv3D(16, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 4)\n",
    "    conv8 = Conv3D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv3D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv3D(8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 4)\n",
    "    conv9 = Conv3D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv3D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv3D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv3D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs, conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 12 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 128, 128, 128 224         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 128, 128, 128 1736        conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 64, 64, 64, 8 0           conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 64, 64, 64, 1 3472        max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 64, 64, 64, 1 6928        conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 32, 32, 32, 1 0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 32, 32, 32, 3 13856       max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 32, 32, 32, 3 27680       conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 16, 16, 16, 3 0           conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 16, 16, 16, 6 55360       max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 16, 16, 16, 6 110656      conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16, 16, 16, 6 0           conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d (UpSampling3D)    (None, 32, 32, 32, 6 0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 32, 32, 32, 3 16416       up_sampling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 32, 6 0           conv3d_5[0][0]                   \n",
      "                                                                 conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 32, 32, 32, 3 55328       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 32, 32, 32, 3 27680       conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)  (None, 64, 64, 64, 3 0           conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 64, 64, 64, 1 4112        up_sampling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 64, 3 0           conv3d_3[0][0]                   \n",
      "                                                                 conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 64, 64, 64, 1 13840       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 64, 64, 64, 1 6928        conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)  (None, 128, 128, 128 0           conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 128, 128, 128 1032        up_sampling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 128 0           conv3d_1[0][0]                   \n",
      "                                                                 conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 128, 128, 128 3464        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 128, 128, 128 1736        conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 128, 128, 128 434         conv3d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 128, 128, 128 3           conv3d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 350,885\n",
      "Trainable params: 350,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = unet3D()\n",
    "model.load_weights(\"model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating label for each of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn.plotting as nplt \n",
    "\n",
    "def generateMask(prediction, threshold=0.5):\n",
    "    \"\"\" Returns prediction as an array containing 0 and 1.\n",
    "        threshold is applied on each values \"\"\"\n",
    "    f = lambda a: 1 if a >= threshold else 0\n",
    "    return np.where(prediction >= threshold, 1, 0).astype(np.int8)\n",
    "\n",
    "def saveMask(data, path, header=None):\n",
    "    img = nib.Nifti1Image(data, np.eye(4))\n",
    "    if header is not None:\n",
    "        img.header = header\n",
    "    nib.save(img, path+\".nii\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = generateMask(model.predict(dataset_data))\n",
    "predictions = predictions.reshape((predictions.shape[0], 128,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving predictions\n",
    "for i in range(len(predictions)):\n",
    "    header = None #TODO\n",
    "    saveMask(prediction[i], \"prediction\"+str(i), header)\n",
    "\n",
    "import nilearn.plotting as nplt \n",
    "nplt.plot_img(\"prediction0.nii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-venv",
   "language": "python",
   "name": "python-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
